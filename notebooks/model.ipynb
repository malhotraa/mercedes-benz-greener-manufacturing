{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV, OrthogonalMatchingPursuitCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import csv\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = '/kaggle/dev/mercedes-benz-greener-manufacturing-data/raw_data'\n",
    "DATA_PATH = '/kaggle/dev/mercedes-benz-greener-manufacturing-data'\n",
    "TRAIN_DATA = os.path.join(RAW_DATA_PATH, 'train.csv')\n",
    "TEST_DATA = os.path.join(RAW_DATA_PATH, 'test.csv')\n",
    "SAMPLE_SUBMISSION = os.path.join(RAW_DATA_PATH, 'sample_submission.csv')\n",
    "SUBMISSION_PATH = os.path.join(DATA_PATH, 'submissions')\n",
    "MODELS_PATH = os.path.join(DATA_PATH, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "test_df = pd.read_csv(TEST_DATA)\n",
    "sample_submission_df = pd.read_csv(SAMPLE_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape (4209, 378)\n",
      "test_df.shape (4209, 377)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "for column in train_columns:\n",
    "    cardinality = len(np.unique(train_df[column]))\n",
    "    if cardinality == 1:\n",
    "        train_df.drop(column, axis=1, inplace=True)\n",
    "        test_df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "train_columns = list(set(train_df.columns) - set(['ID', 'y']))\n",
    "        \n",
    "for f in [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    train_values = set(train_df[f].values)\n",
    "    test_values = set(test_df[f].values)\n",
    "    all_values = list(train_values | test_values)\n",
    "    lbl.fit(all_values) \n",
    "    train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "    test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "    \n",
    "print('train_df.shape', train_df.shape)\n",
    "print('test_df.shape', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape (4209, 438)\n",
      "test_df.shape (4209, 437)\n"
     ]
    }
   ],
   "source": [
    "n_comp = 12\n",
    "\n",
    "# tSVD\n",
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "tsvd_results_train = tsvd.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "tsvd_results_test = tsvd.transform(test_df)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=420)\n",
    "pca2_results_train = pca.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test_df)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=420)\n",
    "ica2_results_train = ica.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test_df)\n",
    "\n",
    "# GRP\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "grp_results_test = grp.transform(test_df)\n",
    "\n",
    "# SRP\n",
    "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "srp_results_train = srp.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "srp_results_test = srp.transform(test_df)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(0, n_comp):\n",
    "    train_df['pca_' + str(i)] = pca2_results_train[:, i]\n",
    "    test_df['pca_' + str(i)] = pca2_results_test[:, i]\n",
    "\n",
    "    train_df['ica_' + str(i)] = ica2_results_train[:, i]\n",
    "    test_df['ica_' + str(i)] = ica2_results_test[:, i]\n",
    "\n",
    "    train_df['tsvd_' + str(i)] = tsvd_results_train[:, i]\n",
    "    test_df['tsvd_' + str(i)] = tsvd_results_test[:, i]\n",
    "\n",
    "    train_df['grp_' + str(i)] = grp_results_train[:, i]\n",
    "    test_df['grp_' + str(i)] = grp_results_test[:, i]\n",
    "\n",
    "    train_df['srp_' + str(i)] = srp_results_train[:, i]\n",
    "    test_df['srp_' + str(i)] = srp_results_test[:, i]\n",
    "\n",
    "print('train_df.shape', train_df.shape)\n",
    "print('test_df.shape', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (4209, 376)\n",
      "Y.shape (4209,)\n",
      "Fold 0\n",
      "Training model-1497972393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.57218156037 val r2 0.632454676266\n",
      "  Saved model-1497972393\n",
      "Fold 1\n",
      "Training model-1497972404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.578769953073 val r2 0.565390879065\n",
      "  Saved model-1497972404\n",
      "Fold 2\n",
      "Training model-1497972416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.608849804974 val r2 0.343535825287\n",
      "  Saved model-1497972416\n",
      "Fold 3\n",
      "Training model-1497972427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.577769593788 val r2 0.586632366997\n",
      "  Saved model-1497972427\n",
      "Fold 4\n",
      "Training model-1497972438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.578320073321 val r2 0.596821003434\n",
      "  Saved model-1497972438\n",
      "Fold 5\n",
      "Training model-1497972449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.574669294919 val r2 0.607040216929\n",
      "  Saved model-1497972449\n",
      "Fold 6\n",
      "Training model-1497972460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.572300491893 val r2 0.645721620161\n",
      "  Saved model-1497972460\n",
      "Fold 7\n",
      "Training model-1497972472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.575280559157 val r2 0.601266582266\n",
      "  Saved model-1497972472\n",
      "Fold 8\n",
      "Training model-1497972483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.573303090482 val r2 0.63519611272\n",
      "  Saved model-1497972483\n",
      "Fold 9\n",
      "Training model-1497972494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train r2 0.578229764318 val r2 0.570065756566\n",
      "  Saved model-1497972494\n",
      "train r2 0.578967 val r2 0.578413\n"
     ]
    }
   ],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "        return X_transformed\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "kf = model_selection.KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "best_errors = {}\n",
    "r2_scores = np.ndarray(shape=[NUM_FOLDS, 2], dtype=np.float32)\n",
    "model_ids = []\n",
    "\n",
    "Y = train_df['y'].values\n",
    "X = train_df[train_columns]\n",
    "Y_mean = np.mean(Y)\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(kf.split(X)):\n",
    "    print('Fold', fold)\n",
    "    \n",
    "    train_X_stacked, val_X_stacked = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    train_Y_stacked, val_Y_stacked = Y[train_idxs], Y[val_idxs]\n",
    "\n",
    "    model_id = \"model-\" + str(int(time.time()))\n",
    "    model_ids.append(model_id)\n",
    "    print('Training', model_id)    \n",
    "    \n",
    "    stacked_pipeline = make_pipeline(\n",
    "        StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "        StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", n_estimators=500, max_depth=3, max_features=0.55, min_samples_leaf=18, min_samples_split=14, subsample=0.9)),\n",
    "        #ExtraTreesRegressor(n_estimators=500, max_features=0.55, max_depth=3, min_samples_leaf=18, min_samples_split=14, n_jobs=-1),\n",
    "        LassoLarsCV())\n",
    "\n",
    "    stacked_pipeline.fit(train_X_stacked, train_Y_stacked)\n",
    "    pickle.dump(stacked_pipeline, open(os.path.join(MODELS_PATH, model_id + \".stacked\"), \"wb\"))\n",
    "    train_Y_stacked_pred = stacked_pipeline.predict(train_X_stacked)\n",
    "    train_r2_score = metrics.r2_score(train_Y_stacked, train_Y_stacked_pred)\n",
    "    val_Y_stacked_pred = stacked_pipeline.predict(val_X_stacked)\n",
    "    val_r2_score = metrics.r2_score(val_Y_stacked, val_Y_stacked_pred)\n",
    "\n",
    "    r2_scores[fold, 0] = train_r2_score\n",
    "    r2_scores[fold, 1] = val_r2_score\n",
    "    print('  train r2', train_r2_score, 'val r2', val_r2_score)\n",
    "    print('  Saved', model_id)\n",
    "    \n",
    "print('train r2', np.mean(r2_scores[:, 0]),\n",
    "      'val r2', np.mean(r2_scores[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (4209, 424)\n",
      "Y.shape (4209,)\n",
      "Fold 0\n",
      "Training model-1497928853\n",
      "  train r2 0.834918220471 val r2 0.587470460682\n",
      "  Saved model-1497928853\n",
      "Fold 1\n",
      "Training model-1497928859\n",
      "  train r2 0.831633303508 val r2 0.53356097117\n",
      "  Saved model-1497928859\n",
      "Fold 2\n",
      "Training model-1497928865\n",
      "  train r2 0.858805314039 val r2 0.317516438311\n",
      "  Saved model-1497928865\n",
      "Fold 3\n",
      "Training model-1497928872\n",
      "  train r2 0.841224381545 val r2 0.553905277812\n",
      "  Saved model-1497928872\n",
      "Fold 4\n",
      "Training model-1497928878\n",
      "  train r2 0.836197535809 val r2 0.588333206693\n",
      "  Saved model-1497928878\n",
      "Fold 5\n",
      "Training model-1497928883\n",
      "  train r2 0.842227217629 val r2 0.609209220178\n",
      "  Saved model-1497928883\n",
      "Fold 6\n",
      "Training model-1497928889\n",
      "  train r2 0.837264033881 val r2 0.624121124766\n",
      "  Saved model-1497928889\n",
      "Fold 7\n",
      "Training model-1497928895\n",
      "  train r2 0.838075084721 val r2 0.594774446669\n",
      "  Saved model-1497928895\n",
      "Fold 8\n",
      "Training model-1497928900\n",
      "  train r2 0.835875943723 val r2 0.612757486423\n",
      "  Saved model-1497928900\n",
      "Fold 9\n",
      "Training model-1497928908\n",
      "  train r2 0.834547187933 val r2 0.556573919386\n",
      "  Saved model-1497928908\n",
      "train r2 0.839077 val r2 0.557822\n"
     ]
    }
   ],
   "source": [
    "NUM_FOLDS = 10\n",
    "kf = model_selection.KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "best_errors = {}\n",
    "r2_scores = np.ndarray(shape=[NUM_FOLDS, 2], dtype=np.float32)\n",
    "model_ids = []\n",
    "\n",
    "Y = train_df['y'].values\n",
    "X = train_df.drop([\"ID\", \"y\"], axis=1)\n",
    "Y_mean = np.mean(Y)\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(kf.split(X)):\n",
    "    print('Fold', fold)\n",
    "    \n",
    "    train_X, val_X = X.iloc[train_idxs], X.iloc[val_idxs]\n",
    "    train_Y, val_Y = Y[train_idxs], Y[val_idxs]\n",
    "\n",
    "    def xgb_r2_score(preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        return 'rmse', -1.0 * metrics.r2_score(labels, preds)\n",
    "\n",
    "    model_id = \"model-\" + str(int(time.time()))\n",
    "    model_ids.append(model_id)\n",
    "    print('Training', model_id)\n",
    "\n",
    "    model = xgb.XGBRegressor(max_depth = 10,\n",
    "                        gamma=0.5,\n",
    "                        objective=\"reg:linear\",\n",
    "                        n_estimators=1000,\n",
    "                        learning_rate=0.005,\n",
    "                        nthread=12,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.70,\n",
    "                        colsample_bylevel=0.70,\n",
    "                        #base_score=Y_mean,\n",
    "                        seed=42,\n",
    "                        silent=True)\n",
    "\n",
    "    model.fit(train_X, train_Y, eval_set=[(train_X, train_Y), (val_X, val_Y)], verbose=False, eval_metric='rmse', early_stopping_rounds=50)\n",
    "    evals_result = model.evals_result()\n",
    "    pickle.dump(model, open(os.path.join(MODELS_PATH, model_id + \".xgb\"), \"wb\"))\n",
    "    train_Y_pred = model.predict(train_X)\n",
    "    train_r2_score = metrics.r2_score(train_Y, train_Y_pred)\n",
    "    val_Y_pred = model.predict(val_X)\n",
    "    val_r2_score = metrics.r2_score(val_Y, val_Y_pred)\n",
    "    r2_scores[fold, 0] = train_r2_score\n",
    "    r2_scores[fold, 1] = val_r2_score\n",
    "    print('  train r2', train_r2_score, 'val r2', val_r2_score)\n",
    "    print('  Saved', model_id)\n",
    "    \n",
    "print('train r2', np.mean(r2_scores[:, 0]),\n",
    "      'val r2', np.mean(r2_scores[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg xgb models predictions\n",
    "\n",
    "test_Y_pred = np.zeros(shape=(test_df.shape[0], 9), dtype=np.float32)\n",
    "\n",
    "pred_count = 0\n",
    "for fold in [0, 1, 3, 4, 5, 6, 7, 8, 9]:\n",
    "    model_id = model_ids[fold]\n",
    "    model = pickle.load(open(os.path.join(MODELS_PATH, model_id + '.xgb'), 'rb'))\n",
    "    test_X = test_df.drop(['ID'], axis=1)\n",
    "    test_Y_pred[:, pred_count] = model.predict(test_X)\n",
    "    pred_count+=1\n",
    "\n",
    "test_Y_avg = np.mean(test_Y_pred, axis=1)\n",
    "test_Y_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg stacked models predictions\n",
    "\n",
    "test_Y_pred = np.zeros(shape=(test_df.shape[0], 9), dtype=np.float32)\n",
    "test_X = test_df[train_columns]\n",
    "\n",
    "pred_count = 0\n",
    "for fold in [0, 1, 3, 4, 5, 6, 7, 8, 9]:\n",
    "    model_id = model_ids[fold]\n",
    "    model = pickle.load(open(os.path.join(MODELS_PATH, model_id + '.stacked'), 'rb'))\n",
    "    test_Y_pred[:, pred_count] = model.predict(test_X)\n",
    "    pred_count+=1\n",
    "\n",
    "test_Y_avg_stacked = np.mean(test_Y_pred, axis=1)\n",
    "test_Y_avg_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model-1497917928, model-1497917949, model-1497917969, model-1497917990, model-1497918010, model-1497918031, model-1497918052, model-1497918072, model-1497918093, model-1497918114'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(model_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted average of predictions\n",
    "test_Y = test_Y_avg * 0.75 + test_Y_avg_stacked * 0.25\n",
    "test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated submission  /kaggle/dev/mercedes-benz-greener-manufacturing-data/submissions/submission-1497928914.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission_df = test_df[['ID']]\n",
    "submission_df['y'] = test_Y_avg_stacked.tolist()\n",
    "submission_df.to_csv(os.path.join(SUBMISSION_PATH, 'submission-' + str(int(time.time())) + '.csv'), index=False)\n",
    "print('Generated submission ', os.path.join(SUBMISSION_PATH, 'submission-' + str(int(time.time())) + '.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
