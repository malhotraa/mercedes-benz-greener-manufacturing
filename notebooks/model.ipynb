{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV, OrthogonalMatchingPursuitCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline, FeatureUnion\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import randint\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import csv\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = '/kaggle/dev/mercedes-benz-greener-manufacturing-data/raw_data'\n",
    "DATA_PATH = '/kaggle/dev/mercedes-benz-greener-manufacturing-data'\n",
    "TRAIN_DATA = os.path.join(RAW_DATA_PATH, 'train.csv')\n",
    "TEST_DATA = os.path.join(RAW_DATA_PATH, 'test.csv')\n",
    "SAMPLE_SUBMISSION = os.path.join(RAW_DATA_PATH, 'sample_submission.csv')\n",
    "SUBMISSION_PATH = os.path.join(DATA_PATH, 'submissions')\n",
    "MODELS_PATH = os.path.join(DATA_PATH, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "test_df = pd.read_csv(TEST_DATA)\n",
    "sample_submission_df = pd.read_csv(SAMPLE_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering outliers\n",
      "train_df.shape (4208, 366)\n",
      "test_df.shape (4209, 365)\n",
      "original columns 364\n",
      "augmented columns 424\n",
      "train_df.shape (4208, 426)\n",
      "test_df.shape (4209, 425)\n"
     ]
    }
   ],
   "source": [
    "filter_outliers = True\n",
    "xgb_use_augment_features = False\n",
    "stacked_use_augment_features = True\n",
    "\n",
    "# Preprocess data\n",
    "for column in train_df.columns:\n",
    "    cardinality = len(np.unique(train_df[column]))\n",
    "    if cardinality == 1:\n",
    "        train_df.drop(column, axis=1, inplace=True)\n",
    "        test_df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "original_train_columns = sorted(list(set(train_df.columns) - set(['ID', 'y'])))\n",
    "        \n",
    "for f in [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    train_values = set(train_df[f].values)\n",
    "    test_values = set(test_df[f].values)\n",
    "    all_values = list(train_values | test_values)\n",
    "    lbl.fit(all_values) \n",
    "    train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "    test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "\n",
    "if filter_outliers:\n",
    "    print('Filtering outliers')\n",
    "    # Filter out outlier y = 265.32\n",
    "    train_df = train_df[train_df.y < 200]\n",
    "\n",
    "print('train_df.shape', train_df.shape)\n",
    "print('test_df.shape', test_df.shape)\n",
    "n_comp = 12\n",
    "\n",
    "# tSVD\n",
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "tsvd_results_train = tsvd.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "tsvd_results_test = tsvd.transform(test_df)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=420)\n",
    "pca2_results_train = pca.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test_df)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=420)\n",
    "ica2_results_train = ica.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test_df)\n",
    "\n",
    "# GRP\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "grp_results_test = grp.transform(test_df)\n",
    "\n",
    "# SRP\n",
    "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "srp_results_train = srp.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "srp_results_test = srp.transform(test_df)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(0, n_comp):\n",
    "    train_df['pca_' + str(i)] = pca2_results_train[:, i]\n",
    "    test_df['pca_' + str(i)] = pca2_results_test[:, i]\n",
    "\n",
    "    train_df['ica_' + str(i)] = ica2_results_train[:, i]\n",
    "    test_df['ica_' + str(i)] = ica2_results_test[:, i]\n",
    "\n",
    "    train_df['tsvd_' + str(i)] = tsvd_results_train[:, i]\n",
    "    test_df['tsvd_' + str(i)] = tsvd_results_test[:, i]\n",
    "\n",
    "    train_df['grp_' + str(i)] = grp_results_train[:, i]\n",
    "    test_df['grp_' + str(i)] = grp_results_test[:, i]\n",
    "\n",
    "    train_df['srp_' + str(i)] = srp_results_train[:, i]\n",
    "    test_df['srp_' + str(i)] = srp_results_test[:, i]\n",
    "\n",
    "augmented_train_columns = sorted(list(set(train_df.columns) - set(['ID', 'y'])))\n",
    "print('original columns', len(original_train_columns))\n",
    "print('augmented columns', len(augmented_train_columns))\n",
    "print('train_df.shape', train_df.shape)\n",
    "print('test_df.shape', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (4208, 424)\n",
      "Y.shape (4208,)\n",
      "train_X.shape (3366, 424)\n",
      "train_Y.shape (3366,)\n",
      "holdout_X.shape (842, 424)\n",
      "holdout_Y.shape (842,)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop([\"ID\", \"y\"], axis=1)\n",
    "Y = train_df['y'].values\n",
    "train_X, holdout_X, train_Y, holdout_Y = model_selection.train_test_split(X, Y, test_size=0.2, random_state=29)\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "print('train_X.shape', train_X.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('holdout_X.shape', holdout_X.shape)\n",
    "print('holdout_Y.shape', holdout_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_stacked.shape (3366, 424)\n",
      "train_Y.shape (3366,)\n",
      "holdout_X_stacked.shape (842, 424)\n",
      "holdout_Y.shape (842,)\n",
      "Fold 0 Training model-1498017343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-bbfda785451f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#ExtraTreesRegressor(n_estimators=500, max_features=0.55, max_depth=3, min_samples_leaf=18, min_samples_split=14, n_jobs=-1),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         LassoLarsCV())\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mstacked_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_X_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_Y_stacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".stacked\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtrain_Y_stacked_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_X_stacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-222-bbfda785451f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "#         if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "#             X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "        return X_transformed\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "kf = model_selection.KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "perf = []\n",
    "\n",
    "if stacked_use_augment_features:\n",
    "    train_X_stacked = train_X[augmented_train_columns]\n",
    "    holdout_X_stacked = holdout_X[augmented_train_columns]\n",
    "    test_X_stacked = test_df[augmented_train_columns]\n",
    "else:\n",
    "    train_X_stacked = train_X[original_train_columns]\n",
    "    holdout_X_stacked = holdout_X[original_train_columns]\n",
    "    test_X_stacked = test_df[original_train_columns]\n",
    "\n",
    "print('train_X_stacked.shape', train_X_stacked.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('holdout_X_stacked.shape', holdout_X_stacked.shape)\n",
    "print('holdout_Y.shape', holdout_Y.shape)\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(kf.split(train_X_stacked)):\n",
    "    model_id = \"model-\" + str(int(time.time()))\n",
    "    print('Fold {} Training {}'.format(fold, model_id))\n",
    "    \n",
    "    trn_X_stacked, val_X_stacked = train_X_stacked.iloc[train_idxs], train_X_stacked.iloc[val_idxs]\n",
    "    trn_Y_stacked, val_Y_stacked = train_Y[train_idxs], train_Y[val_idxs]\n",
    "    \n",
    "    stacked_pipeline = make_pipeline(\n",
    "        StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "        StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\",\n",
    "                                                              n_estimators=500, max_depth=3,\n",
    "                                                              max_features=0.55, min_samples_leaf=18,\n",
    "                                                              min_samples_split=14, subsample=0.7)),\n",
    "        #ExtraTreesRegressor(n_estimators=500, max_features=0.55, max_depth=3, min_samples_leaf=18, min_samples_split=14, n_jobs=-1),\n",
    "        LassoLarsCV())\n",
    "    stacked_pipeline.fit(trn_X_stacked, trn_Y_stacked)\n",
    "    pickle.dump(stacked_pipeline, open(os.path.join(MODELS_PATH, model_id + \".stacked\"), \"wb\"))\n",
    "    train_Y_stacked_pred = stacked_pipeline.predict(trn_X_stacked)\n",
    "    train_r2_score = metrics.r2_score(trn_Y_stacked, train_Y_stacked_pred)\n",
    "    val_Y_stacked_pred = stacked_pipeline.predict(val_X_stacked)\n",
    "    val_r2_score = metrics.r2_score(val_Y_stacked, val_Y_stacked_pred)\n",
    "    holdout_Y_pred = stacked_pipeline.predict(holdout_X_stacked)\n",
    "    holdout_r2_score = metrics.r2_score(holdout_Y, holdout_Y_pred)\n",
    "    perf.append((fold, model_id, train_r2_score, val_r2_score, holdout_r2_score))\n",
    "\n",
    "perf_stacked_df = pd.DataFrame(perf, columns=['fold', 'model_id', 'train_r2', 'validation_r2', 'holdout_r2'])\n",
    "print('avg train r2', perf_stacked_df['train_r2'].mean(),\n",
    "      'avg validation r2', perf_stacked_df['validation_r2'].mean(), \n",
    "      'avg holdout r2', perf_stacked_df['holdout_r2'].mean())\n",
    "perf_stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_stacked.shape (3366, 424)\n",
      "train_Y.shape (3366,)\n",
      "holdout_X_stacked.shape (842, 424)\n",
      "holdout_Y.shape (842,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2 0.612745639267 holdout R2 0.591186224207\n"
     ]
    }
   ],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "#         if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "#             X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "        return X_transformed\n",
    "\n",
    "if stacked_use_augment_features:\n",
    "    train_X_stacked = train_X[augmented_train_columns]\n",
    "    holdout_X_stacked = holdout_X[augmented_train_columns]\n",
    "    test_X_stacked = test_df[augmented_train_columns]\n",
    "else:\n",
    "    train_X_stacked = train_X[original_train_columns]\n",
    "    holdout_X_stacked = holdout_X[original_train_columns]\n",
    "    test_X_stacked = test_df[original_train_columns]\n",
    "\n",
    "print('train_X_stacked.shape', train_X_stacked.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('holdout_X_stacked.shape', holdout_X_stacked.shape)\n",
    "print('holdout_Y.shape', holdout_Y.shape)\n",
    "\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\",\n",
    "                                                          n_estimators=500, max_depth=3,\n",
    "                                                          max_features=0.55, min_samples_leaf=18,\n",
    "                                                          min_samples_split=14, subsample=0.7)),\n",
    "    LassoLarsCV())\n",
    "stacked_pipeline.fit(train_X_stacked, train_Y)\n",
    "train_Y_stacked_pred = stacked_pipeline.predict(train_X_stacked)\n",
    "train_r2_score = metrics.r2_score(train_Y, train_Y_stacked_pred)\n",
    "holdout_Y_stacked_pred = stacked_pipeline.predict(holdout_X_stacked)\n",
    "holdout_r2_score = metrics.r2_score(holdout_Y, holdout_Y_stacked_pred)\n",
    "    \n",
    "print('train R2', train_r2_score, 'holdout R2', holdout_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_xgb.shape (3366, 364)\n",
      "train_Y.shape (3366,)\n",
      "holdout_X_xgb.shape (842, 364)\n",
      "holdout_Y.shape (842,)\n",
      "test_X_xgb.shape (4209, 364) \n",
      "\n",
      "Fold 0 Training model-1498017372\n",
      "Fold 1 Training model-1498017376\n",
      "Fold 2 Training model-1498017379\n",
      "Fold 3 Training model-1498017383\n",
      "Fold 4 Training model-1498017386\n",
      "Fold 5 Training model-1498017389\n",
      "Fold 6 Training model-1498017393\n",
      "Fold 7 Training model-1498017396\n",
      "Fold 8 Training model-1498017400\n",
      "Fold 9 Training model-1498017403\n",
      "avg train r2 0.782674286221 avg validation r2 0.574559045576 avg holdout r2 0.568158969746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>validation_r2</th>\n",
       "      <th>holdout_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model-1498017372</td>\n",
       "      <td>0.778743</td>\n",
       "      <td>0.666772</td>\n",
       "      <td>0.571399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>model-1498017376</td>\n",
       "      <td>0.782076</td>\n",
       "      <td>0.516920</td>\n",
       "      <td>0.566121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>model-1498017379</td>\n",
       "      <td>0.781809</td>\n",
       "      <td>0.627925</td>\n",
       "      <td>0.572334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>model-1498017383</td>\n",
       "      <td>0.755803</td>\n",
       "      <td>0.669401</td>\n",
       "      <td>0.569425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>model-1498017386</td>\n",
       "      <td>0.780663</td>\n",
       "      <td>0.594206</td>\n",
       "      <td>0.569809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>model-1498017389</td>\n",
       "      <td>0.808240</td>\n",
       "      <td>0.452921</td>\n",
       "      <td>0.560852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>model-1498017393</td>\n",
       "      <td>0.783474</td>\n",
       "      <td>0.526206</td>\n",
       "      <td>0.569820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>model-1498017396</td>\n",
       "      <td>0.795202</td>\n",
       "      <td>0.478438</td>\n",
       "      <td>0.565369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>model-1498017400</td>\n",
       "      <td>0.785030</td>\n",
       "      <td>0.641142</td>\n",
       "      <td>0.561955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>model-1498017403</td>\n",
       "      <td>0.775703</td>\n",
       "      <td>0.571660</td>\n",
       "      <td>0.574505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold          model_id  train_r2  validation_r2  holdout_r2\n",
       "0     0  model-1498017372  0.778743       0.666772    0.571399\n",
       "1     1  model-1498017376  0.782076       0.516920    0.566121\n",
       "2     2  model-1498017379  0.781809       0.627925    0.572334\n",
       "3     3  model-1498017383  0.755803       0.669401    0.569425\n",
       "4     4  model-1498017386  0.780663       0.594206    0.569809\n",
       "5     5  model-1498017389  0.808240       0.452921    0.560852\n",
       "6     6  model-1498017393  0.783474       0.526206    0.569820\n",
       "7     7  model-1498017396  0.795202       0.478438    0.565369\n",
       "8     8  model-1498017400  0.785030       0.641142    0.561955\n",
       "9     9  model-1498017403  0.775703       0.571660    0.574505"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FOLDS = 10\n",
    "kf = model_selection.KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "perf = []\n",
    "\n",
    "train_X_original_columns = train_X[original_train_columns]\n",
    "holdout_X_original_columns = holdout_X[original_train_columns]\n",
    "\n",
    "if xgb_use_augment_features:\n",
    "    train_X_xgb = train_X[augmented_train_columns]\n",
    "    test_X_xgb = test_df[augmented_train_columns]\n",
    "    holdout_X_xgb = holdout_X[augmented_train_columns]\n",
    "else:\n",
    "    train_X_xgb = train_X[original_train_columns]\n",
    "    test_X_xgb = test_df[original_train_columns]\n",
    "    holdout_X_xgb = holdout_X[original_train_columns]\n",
    "\n",
    "print('train_X_xgb.shape', train_X_xgb.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('holdout_X_xgb.shape', holdout_X_xgb.shape)\n",
    "print('holdout_Y.shape', holdout_Y.shape)\n",
    "print('test_X_xgb.shape', test_X_xgb.shape, '\\n')\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(kf.split(train_X_xgb)):\n",
    "    model_id = \"model-\" + str(int(time.time()))\n",
    "    print('Fold {} Training {}'.format(fold, model_id))\n",
    "    \n",
    "    trn_X, val_X = train_X_xgb.iloc[train_idxs], train_X_xgb.iloc[val_idxs]\n",
    "    trn_Y, val_Y = train_Y[train_idxs], train_Y[val_idxs]\n",
    "\n",
    "    def xgb_r2_score(preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        return 'rmse', -1.0 * metrics.r2_score(labels, preds)\n",
    "\n",
    "    model = xgb.XGBRegressor(max_depth = 10,\n",
    "                        gamma=0.5,\n",
    "                        objective=\"reg:linear\",\n",
    "                        n_estimators=1000,\n",
    "                        learning_rate=0.005,\n",
    "                        nthread=12,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.70,\n",
    "                        colsample_bylevel=0.70,\n",
    "                        #base_score=Y_mean,\n",
    "                        seed=42,\n",
    "                        silent=True)\n",
    "\n",
    "    model.fit(trn_X, trn_Y, eval_set=[(trn_X, trn_Y), (val_X, val_Y)], verbose=False, eval_metric='rmse', early_stopping_rounds=50)\n",
    "    evals_result = model.evals_result()\n",
    "    pickle.dump(model, open(os.path.join(MODELS_PATH, model_id + \".xgb\"), \"wb\"))\n",
    "    train_Y_pred = model.predict(trn_X)\n",
    "    train_r2_score = metrics.r2_score(trn_Y, train_Y_pred)\n",
    "    val_Y_pred = model.predict(val_X)\n",
    "    val_r2_score = metrics.r2_score(val_Y, val_Y_pred)\n",
    "    holdout_Y_pred = model.predict(holdout_X_xgb)\n",
    "    holdout_r2_score = metrics.r2_score(holdout_Y, holdout_Y_pred)\n",
    "    perf.append((fold, model_id, train_r2_score, val_r2_score, holdout_r2_score))\n",
    "\n",
    "perf_df = pd.DataFrame(perf, columns=['fold', 'model_id', 'train_r2', 'validation_r2', 'holdout_r2'])\n",
    "print('avg train r2', perf_df['train_r2'].mean(),\n",
    "      'avg validation r2', perf_df['validation_r2'].mean(), \n",
    "      'avg holdout r2', perf_df['holdout_r2'].mean())\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg xgb models predictions\n",
    "VALIDATION_THRESHOLD = 0.4\n",
    "NUM_MODELS = perf_df[perf_df.validation_r2 > VALIDATION_THRESHOLD].shape[0]\n",
    "holdout_Y_pred = np.zeros(shape=(holdout_X.shape[0], NUM_MODELS), dtype=np.float32)\n",
    "test_Y_pred = np.zeros(shape=(test_df.shape[0], NUM_MODELS), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for row in perf_df.itertuples():\n",
    "    fold, model_id, train_r2, validation_r2 = row[1], row[2], row[3], row[4]\n",
    "    if validation_r2 < VALIDATION_THRESHOLD:\n",
    "        continue\n",
    "    model = pickle.load(open(os.path.join(MODELS_PATH, model_id + '.xgb'), 'rb'))\n",
    "    test_Y_pred[:, count] = model.predict(test_X_xgb)\n",
    "    holdout_Y_pred[:, count] = model.predict(holdout_X_xgb)\n",
    "    count += 1\n",
    "\n",
    "holdout_Y_avg = np.mean(holdout_Y_pred, axis=1)\n",
    "test_Y_avg = np.mean(test_Y_pred, axis=1)\n",
    "test_Y_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg stacked models predictions\n",
    "VALIDATION_THRESHOLD = 0.4\n",
    "NUM_MODELS = perf_stacked_df[perf_stacked_df.validation_r2 > VALIDATION_THRESHOLD].shape[0]\n",
    "holdout_Y_pred = np.zeros(shape=(holdout_X.shape[0], NUM_MODELS), dtype=np.float32)\n",
    "test_Y_pred = np.zeros(shape=(test_df.shape[0], NUM_MODELS), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for row in perf_stacked_df.itertuples():\n",
    "    fold, model_id, train_r2, validation_r2 = row[1], row[2], row[3], row[4]\n",
    "    if validation_r2 < 0.4:\n",
    "        continue\n",
    "    model = pickle.load(open(os.path.join(MODELS_PATH, model_id + '.stacked'), 'rb'))\n",
    "    test_Y_pred[:, count] = model.predict(test_X_stacked)\n",
    "    holdout_Y_pred[:, count] = model.predict(holdout_X_stacked)\n",
    "    count += 1\n",
    "\n",
    "holdout_Y_avg_stacked = np.mean(holdout_Y_pred, axis=1)\n",
    "test_Y_avg_stacked = np.mean(test_Y_pred, axis=1)\n",
    "test_Y_avg_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single stacked model prediction\n",
    "stacked_Y = stacked_pipeline.predict(test_X_stacked)\n",
    "stacked_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holdout_r2_ensemble 0.583066122756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted average of predictions\n",
    "holdout_Y_ensembled = holdout_Y_avg * 0.5 + holdout_Y_avg_stacked * 0.5\n",
    "holdout_r2_ensemble = metrics.r2_score(holdout_Y, holdout_Y_ensembled)\n",
    "print('holdout_r2_ensemble', holdout_r2_ensemble)\n",
    "test_Y_ensemble_1 = test_Y_avg * 0.5 + stacked_Y * 0.5\n",
    "test_Y_ensemble_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holdout_r2_ensemble 0.587689411042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted average of predictions\n",
    "holdout_Y_ensembled = holdout_Y_avg * 0.5 + holdout_Y_stacked_pred * 0.5\n",
    "holdout_r2_ensemble = metrics.r2_score(holdout_Y, holdout_Y_ensembled)\n",
    "print('holdout_r2_ensemble', holdout_r2_ensemble)\n",
    "test_Y_ensemble_2 = test_Y_avg * 0.5 + stacked_Y * 0.5\n",
    "test_Y_ensemble_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated submission  /kaggle/dev/mercedes-benz-greener-manufacturing-data/submissions/submission-1498017417.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission_df = test_df[['ID']]\n",
    "submission_df['y'] = test_Y_ensemble_2.tolist()\n",
    "submission_df.to_csv(os.path.join(SUBMISSION_PATH, 'submission-' + str(int(time.time())) + '.csv'), index=False)\n",
    "print('Generated submission ', os.path.join(SUBMISSION_PATH, 'submission-' + str(int(time.time())) + '.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
