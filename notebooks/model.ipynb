{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV, OrthogonalMatchingPursuitCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline, FeatureUnion\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import randint\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import csv\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = '/kaggle/dev/mercedes-benz-greener-manufacturing-data/raw_data'\n",
    "DATA_PATH = '/kaggle/dev/mercedes-benz-greener-manufacturing-data'\n",
    "TRAIN_DATA = os.path.join(RAW_DATA_PATH, 'train.csv')\n",
    "TEST_DATA = os.path.join(RAW_DATA_PATH, 'test.csv')\n",
    "SAMPLE_SUBMISSION = os.path.join(RAW_DATA_PATH, 'sample_submission.csv')\n",
    "SUBMISSION_PATH = os.path.join(DATA_PATH, 'submissions')\n",
    "MODELS_PATH = os.path.join(DATA_PATH, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA)\n",
    "test_df = pd.read_csv(TEST_DATA)\n",
    "sample_submission_df = pd.read_csv(SAMPLE_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering outliers\n",
      "train_df.shape (4208, 366)\n",
      "test_df.shape (4209, 365)\n",
      "original columns 364\n",
      "augmented columns 424\n",
      "train_df.shape (4208, 426)\n",
      "test_df.shape (4209, 425)\n"
     ]
    }
   ],
   "source": [
    "filter_outliers = True\n",
    "xgb_use_augment_features = False\n",
    "stacked_use_augment_features = True\n",
    "\n",
    "# Preprocess data\n",
    "for column in train_df.columns:\n",
    "    cardinality = len(np.unique(train_df[column]))\n",
    "    if cardinality == 1:\n",
    "        train_df.drop(column, axis=1, inplace=True)\n",
    "        test_df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "original_train_columns = sorted(list(set(train_df.columns) - set(['ID', 'y'])))\n",
    "        \n",
    "for f in [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    train_values = set(train_df[f].values)\n",
    "    test_values = set(test_df[f].values)\n",
    "    all_values = list(train_values | test_values)\n",
    "    lbl.fit(all_values) \n",
    "    train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "    test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "\n",
    "if filter_outliers:\n",
    "    print('Filtering outliers')\n",
    "    # Filter out outlier y = 265.32\n",
    "    train_df = train_df[train_df.y < 200]\n",
    "\n",
    "print('train_df.shape', train_df.shape)\n",
    "print('test_df.shape', test_df.shape)\n",
    "n_comp = 12\n",
    "\n",
    "# tSVD\n",
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "tsvd_results_train = tsvd.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "tsvd_results_test = tsvd.transform(test_df)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=420)\n",
    "pca2_results_train = pca.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(test_df)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=420)\n",
    "ica2_results_train = ica.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(test_df)\n",
    "\n",
    "# GRP\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "grp_results_test = grp.transform(test_df)\n",
    "\n",
    "# SRP\n",
    "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "srp_results_train = srp.fit_transform(train_df.drop([\"y\"], axis=1))\n",
    "srp_results_test = srp.transform(test_df)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(0, n_comp):\n",
    "    train_df['pca_' + str(i)] = pca2_results_train[:, i]\n",
    "    test_df['pca_' + str(i)] = pca2_results_test[:, i]\n",
    "\n",
    "    train_df['ica_' + str(i)] = ica2_results_train[:, i]\n",
    "    test_df['ica_' + str(i)] = ica2_results_test[:, i]\n",
    "\n",
    "    train_df['tsvd_' + str(i)] = tsvd_results_train[:, i]\n",
    "    test_df['tsvd_' + str(i)] = tsvd_results_test[:, i]\n",
    "\n",
    "    train_df['grp_' + str(i)] = grp_results_train[:, i]\n",
    "    test_df['grp_' + str(i)] = grp_results_test[:, i]\n",
    "\n",
    "    train_df['srp_' + str(i)] = srp_results_train[:, i]\n",
    "    test_df['srp_' + str(i)] = srp_results_test[:, i]\n",
    "\n",
    "augmented_train_columns = sorted(list(set(train_df.columns) - set(['ID', 'y'])))\n",
    "print('original columns', len(original_train_columns))\n",
    "print('augmented columns', len(augmented_train_columns))\n",
    "print('train_df.shape', train_df.shape)\n",
    "print('test_df.shape', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (4208, 424)\n",
      "Y.shape (4208,)\n",
      "train_X.shape (3366, 424)\n",
      "train_Y.shape (3366,)\n",
      "holdout_X.shape (842, 424)\n",
      "holdout_Y.shape (842,)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop([\"ID\", \"y\"], axis=1)\n",
    "Y = train_df['y'].values\n",
    "train_X, holdout_X, train_Y, holdout_Y = model_selection.train_test_split(X, Y, test_size=0.2, random_state=29)\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "print('train_X.shape', train_X.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('holdout_X.shape', holdout_X.shape)\n",
    "print('holdout_Y.shape', holdout_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_stacked.shape (3366, 424)\n",
      "train_Y.shape (3366,)\n",
      "holdout_X_stacked.shape (842, 424)\n",
      "holdout_Y.shape (842,)\n",
      "Fold 0 Training model-1498061991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Training model-1498062003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Training model-1498062014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Training model-1498062025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Training model-1498062037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Training model-1498062048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 Training model-1498062060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 Training model-1498062071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 Training model-1498062082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 Training model-1498062093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg train r2 0.612225491464 avg validation r2 0.599630696363 avg holdout r2 0.589464914707\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>validation_r2</th>\n",
       "      <th>holdout_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model-1498061991</td>\n",
       "      <td>0.604479</td>\n",
       "      <td>0.681476</td>\n",
       "      <td>0.587035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>model-1498062003</td>\n",
       "      <td>0.619481</td>\n",
       "      <td>0.541933</td>\n",
       "      <td>0.590708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>model-1498062014</td>\n",
       "      <td>0.606163</td>\n",
       "      <td>0.658690</td>\n",
       "      <td>0.589458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>model-1498062025</td>\n",
       "      <td>0.603385</td>\n",
       "      <td>0.663311</td>\n",
       "      <td>0.590640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>model-1498062037</td>\n",
       "      <td>0.609703</td>\n",
       "      <td>0.619665</td>\n",
       "      <td>0.590944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>model-1498062048</td>\n",
       "      <td>0.618877</td>\n",
       "      <td>0.500446</td>\n",
       "      <td>0.586479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>model-1498062060</td>\n",
       "      <td>0.620761</td>\n",
       "      <td>0.537532</td>\n",
       "      <td>0.593470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>model-1498062071</td>\n",
       "      <td>0.622527</td>\n",
       "      <td>0.520586</td>\n",
       "      <td>0.587939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>model-1498062082</td>\n",
       "      <td>0.603501</td>\n",
       "      <td>0.680335</td>\n",
       "      <td>0.587390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>model-1498062093</td>\n",
       "      <td>0.613380</td>\n",
       "      <td>0.592334</td>\n",
       "      <td>0.590586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold          model_id  train_r2  validation_r2  holdout_r2\n",
       "0     0  model-1498061991  0.604479       0.681476    0.587035\n",
       "1     1  model-1498062003  0.619481       0.541933    0.590708\n",
       "2     2  model-1498062014  0.606163       0.658690    0.589458\n",
       "3     3  model-1498062025  0.603385       0.663311    0.590640\n",
       "4     4  model-1498062037  0.609703       0.619665    0.590944\n",
       "5     5  model-1498062048  0.618877       0.500446    0.586479\n",
       "6     6  model-1498062060  0.620761       0.537532    0.593470\n",
       "7     7  model-1498062071  0.622527       0.520586    0.587939\n",
       "8     8  model-1498062082  0.603501       0.680335    0.587390\n",
       "9     9  model-1498062093  0.613380       0.592334    0.590586"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "#         if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "#             X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "        return X_transformed\n",
    "\n",
    "NUM_FOLDS = 10\n",
    "kf = model_selection.KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "perf = []\n",
    "\n",
    "if stacked_use_augment_features:\n",
    "    train_X_stacked = train_X[augmented_train_columns]\n",
    "    holdout_X_stacked = holdout_X[augmented_train_columns]\n",
    "    test_X_stacked = test_df[augmented_train_columns]\n",
    "else:\n",
    "    train_X_stacked = train_X[original_train_columns]\n",
    "    holdout_X_stacked = holdout_X[original_train_columns]\n",
    "    test_X_stacked = test_df[original_train_columns]\n",
    "\n",
    "print('train_X_stacked.shape', train_X_stacked.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('holdout_X_stacked.shape', holdout_X_stacked.shape)\n",
    "print('holdout_Y.shape', holdout_Y.shape)\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(kf.split(train_X_stacked)):\n",
    "    model_id = \"model-\" + str(int(time.time()))\n",
    "    print('Fold {} Training {}'.format(fold, model_id))\n",
    "    \n",
    "    trn_X_stacked, val_X_stacked = train_X_stacked.iloc[train_idxs], train_X_stacked.iloc[val_idxs]\n",
    "    trn_Y_stacked, val_Y_stacked = train_Y[train_idxs], train_Y[val_idxs]\n",
    "    \n",
    "    stacked_pipeline = make_pipeline(\n",
    "        StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "        StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\",\n",
    "                                                              n_estimators=500, max_depth=3,\n",
    "                                                              max_features=0.55, min_samples_leaf=18,\n",
    "                                                              min_samples_split=14, subsample=0.7)),\n",
    "#         ExtraTreesRegressor(n_estimators=500, max_features=0.55,\n",
    "#                             max_depth=3, min_samples_leaf=18,\n",
    "#                             min_samples_split=14, n_jobs=-1),\n",
    "        LassoLarsCV())\n",
    "    stacked_pipeline.fit(trn_X_stacked, trn_Y_stacked)\n",
    "    pickle.dump(stacked_pipeline, open(os.path.join(MODELS_PATH, model_id + \".stacked\"), \"wb\"))\n",
    "    train_Y_stacked_pred = stacked_pipeline.predict(trn_X_stacked)\n",
    "    train_r2_score = metrics.r2_score(trn_Y_stacked, train_Y_stacked_pred)\n",
    "    val_Y_stacked_pred = stacked_pipeline.predict(val_X_stacked)\n",
    "    val_r2_score = metrics.r2_score(val_Y_stacked, val_Y_stacked_pred)\n",
    "    holdout_Y_pred = stacked_pipeline.predict(holdout_X_stacked)\n",
    "    holdout_r2_score = metrics.r2_score(holdout_Y, holdout_Y_pred)\n",
    "    perf.append((fold, model_id, train_r2_score, val_r2_score, holdout_r2_score))\n",
    "\n",
    "perf_stacked_df = pd.DataFrame(perf, columns=['fold', 'model_id', 'train_r2', 'validation_r2', 'holdout_r2'])\n",
    "print('avg train r2', perf_stacked_df['train_r2'].mean(),\n",
    "      'avg validation r2', perf_stacked_df['validation_r2'].mean(), \n",
    "      'avg holdout r2', perf_stacked_df['holdout_r2'].mean())\n",
    "perf_stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_stacked.shape (3366, 424)\n",
      "train_Y.shape (3366,)\n",
      "holdout_X_stacked.shape (842, 424)\n",
      "holdout_Y.shape (842,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:377: RuntimeWarning: overflow encountered in true_divide\n",
      "  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny))\n",
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/sklearn/linear_model/least_angle.py:381: RuntimeWarning: overflow encountered in true_divide\n",
      "  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2 0.613272076897 holdout R2 0.591621963838\n"
     ]
    }
   ],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "        return X_transformed\n",
    "\n",
    "if stacked_use_augment_features:\n",
    "    train_X_stacked = train_X[augmented_train_columns]\n",
    "    holdout_X_stacked = holdout_X[augmented_train_columns]\n",
    "    test_X_stacked = test_df[augmented_train_columns]\n",
    "else:\n",
    "    train_X_stacked = train_X[original_train_columns]\n",
    "    holdout_X_stacked = holdout_X[original_train_columns]\n",
    "    test_X_stacked = test_df[original_train_columns]\n",
    "\n",
    "print('train_X_stacked.shape', train_X_stacked.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('holdout_X_stacked.shape', holdout_X_stacked.shape)\n",
    "print('holdout_Y.shape', holdout_Y.shape)\n",
    "\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\",\n",
    "                                                          n_estimators=500, max_depth=3,\n",
    "                                                          max_features=0.55, min_samples_leaf=18,\n",
    "                                                          min_samples_split=14, subsample=0.7)),\n",
    "    LassoLarsCV())\n",
    "stacked_pipeline.fit(train_X_stacked, train_Y)\n",
    "train_Y_stacked_pred = stacked_pipeline.predict(train_X_stacked)\n",
    "train_r2_score = metrics.r2_score(train_Y, train_Y_stacked_pred)\n",
    "holdout_Y_stacked_pred = stacked_pipeline.predict(holdout_X_stacked)\n",
    "holdout_r2_score = metrics.r2_score(holdout_Y, holdout_Y_stacked_pred)\n",
    "\n",
    "print('train R2', train_r2_score, 'holdout R2', holdout_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_xgb.shape (3366, 364)\n",
      "train_Y.shape (3366,)\n",
      "holdout_X_xgb.shape (842, 364)\n",
      "holdout_Y.shape (842,)\n",
      "test_X_xgb.shape (4209, 364) \n",
      "\n",
      "Fold 0 Training model-1498059343\n",
      "Fold 1 Training model-1498059347\n",
      "Fold 2 Training model-1498059350\n",
      "Fold 3 Training model-1498059353\n",
      "Fold 4 Training model-1498059357\n",
      "Fold 5 Training model-1498059360\n",
      "Fold 6 Training model-1498059364\n",
      "Fold 7 Training model-1498059367\n",
      "Fold 8 Training model-1498059370\n",
      "Fold 9 Training model-1498059374\n",
      "avg train r2 0.782674286221 avg validation r2 0.574559045576 avg holdout r2 0.568158969746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>validation_r2</th>\n",
       "      <th>holdout_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model-1498059343</td>\n",
       "      <td>0.778743</td>\n",
       "      <td>0.666772</td>\n",
       "      <td>0.571399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>model-1498059347</td>\n",
       "      <td>0.782076</td>\n",
       "      <td>0.516920</td>\n",
       "      <td>0.566121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>model-1498059350</td>\n",
       "      <td>0.781809</td>\n",
       "      <td>0.627925</td>\n",
       "      <td>0.572334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>model-1498059353</td>\n",
       "      <td>0.755803</td>\n",
       "      <td>0.669401</td>\n",
       "      <td>0.569425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>model-1498059357</td>\n",
       "      <td>0.780663</td>\n",
       "      <td>0.594206</td>\n",
       "      <td>0.569809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>model-1498059360</td>\n",
       "      <td>0.808240</td>\n",
       "      <td>0.452921</td>\n",
       "      <td>0.560852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>model-1498059364</td>\n",
       "      <td>0.783474</td>\n",
       "      <td>0.526206</td>\n",
       "      <td>0.569820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>model-1498059367</td>\n",
       "      <td>0.795202</td>\n",
       "      <td>0.478438</td>\n",
       "      <td>0.565369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>model-1498059370</td>\n",
       "      <td>0.785030</td>\n",
       "      <td>0.641142</td>\n",
       "      <td>0.561955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>model-1498059374</td>\n",
       "      <td>0.775703</td>\n",
       "      <td>0.571660</td>\n",
       "      <td>0.574505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold          model_id  train_r2  validation_r2  holdout_r2\n",
       "0     0  model-1498059343  0.778743       0.666772    0.571399\n",
       "1     1  model-1498059347  0.782076       0.516920    0.566121\n",
       "2     2  model-1498059350  0.781809       0.627925    0.572334\n",
       "3     3  model-1498059353  0.755803       0.669401    0.569425\n",
       "4     4  model-1498059357  0.780663       0.594206    0.569809\n",
       "5     5  model-1498059360  0.808240       0.452921    0.560852\n",
       "6     6  model-1498059364  0.783474       0.526206    0.569820\n",
       "7     7  model-1498059367  0.795202       0.478438    0.565369\n",
       "8     8  model-1498059370  0.785030       0.641142    0.561955\n",
       "9     9  model-1498059374  0.775703       0.571660    0.574505"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FOLDS = 10\n",
    "kf = model_selection.KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "perf = []\n",
    "\n",
    "train_X_original_columns = train_X[original_train_columns]\n",
    "holdout_X_original_columns = holdout_X[original_train_columns]\n",
    "\n",
    "if xgb_use_augment_features:\n",
    "    train_X_xgb = train_X[augmented_train_columns]\n",
    "    test_X_xgb = test_df[augmented_train_columns]\n",
    "    holdout_X_xgb = holdout_X[augmented_train_columns]\n",
    "else:\n",
    "    train_X_xgb = train_X[original_train_columns]\n",
    "    test_X_xgb = test_df[original_train_columns]\n",
    "    holdout_X_xgb = holdout_X[original_train_columns]\n",
    "\n",
    "print('train_X_xgb.shape', train_X_xgb.shape)\n",
    "print('train_Y.shape', train_Y.shape)\n",
    "print('holdout_X_xgb.shape', holdout_X_xgb.shape)\n",
    "print('holdout_Y.shape', holdout_Y.shape)\n",
    "print('test_X_xgb.shape', test_X_xgb.shape, '\\n')\n",
    "\n",
    "for fold, (train_idxs, val_idxs) in enumerate(kf.split(train_X_xgb)):\n",
    "    model_id = \"model-\" + str(int(time.time()))\n",
    "    print('Fold {} Training {}'.format(fold, model_id))\n",
    "    \n",
    "    trn_X, val_X = train_X_xgb.iloc[train_idxs], train_X_xgb.iloc[val_idxs]\n",
    "    trn_Y, val_Y = train_Y[train_idxs], train_Y[val_idxs]\n",
    "\n",
    "    def xgb_r2_score(preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        return 'rmse', -1.0 * metrics.r2_score(labels, preds)\n",
    "\n",
    "    model = xgb.XGBRegressor(max_depth = 10,\n",
    "                        gamma=0.5,\n",
    "                        objective=\"reg:linear\",\n",
    "                        n_estimators=1000,\n",
    "                        learning_rate=0.005,\n",
    "                        nthread=12,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.70,\n",
    "                        colsample_bylevel=0.70,\n",
    "                        #base_score=Y_mean,\n",
    "                        seed=42,\n",
    "                        silent=True)\n",
    "\n",
    "    model.fit(trn_X, trn_Y, eval_set=[(trn_X, trn_Y), (val_X, val_Y)], verbose=False, eval_metric='rmse', early_stopping_rounds=50)\n",
    "    evals_result = model.evals_result()\n",
    "    pickle.dump(model, open(os.path.join(MODELS_PATH, model_id + \".xgb\"), \"wb\"))\n",
    "    train_Y_pred = model.predict(trn_X)\n",
    "    train_r2_score = metrics.r2_score(trn_Y, train_Y_pred)\n",
    "    val_Y_pred = model.predict(val_X)\n",
    "    val_r2_score = metrics.r2_score(val_Y, val_Y_pred)\n",
    "    holdout_Y_pred = model.predict(holdout_X_xgb)\n",
    "    holdout_r2_score = metrics.r2_score(holdout_Y, holdout_Y_pred)\n",
    "    perf.append((fold, model_id, train_r2_score, val_r2_score, holdout_r2_score))\n",
    "\n",
    "perf_df = pd.DataFrame(perf, columns=['fold', 'model_id', 'train_r2', 'validation_r2', 'holdout_r2'])\n",
    "print('avg train r2', perf_df['train_r2'].mean(),\n",
    "      'avg validation r2', perf_df['validation_r2'].mean(), \n",
    "      'avg holdout r2', perf_df['holdout_r2'].mean())\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg xgb models predictions\n",
    "VALIDATION_THRESHOLD = 0.4\n",
    "NUM_MODELS = perf_df[perf_df.validation_r2 > VALIDATION_THRESHOLD].shape[0]\n",
    "holdout_Y_pred = np.zeros(shape=(holdout_X.shape[0], NUM_MODELS), dtype=np.float32)\n",
    "test_Y_pred = np.zeros(shape=(test_df.shape[0], NUM_MODELS), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for row in perf_df.itertuples():\n",
    "    fold, model_id, train_r2, validation_r2 = row[1], row[2], row[3], row[4]\n",
    "    if validation_r2 < VALIDATION_THRESHOLD:\n",
    "        continue\n",
    "    model = pickle.load(open(os.path.join(MODELS_PATH, model_id + '.xgb'), 'rb'))\n",
    "    test_Y_pred[:, count] = model.predict(test_X_xgb)\n",
    "    holdout_Y_pred[:, count] = model.predict(holdout_X_xgb)\n",
    "    count += 1\n",
    "\n",
    "holdout_Y_avg = np.mean(holdout_Y_pred, axis=1)\n",
    "test_Y_avg = np.mean(test_Y_pred, axis=1)\n",
    "test_Y_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg stacked models predictions\n",
    "VALIDATION_THRESHOLD = 0.4\n",
    "NUM_MODELS = perf_stacked_df[perf_stacked_df.validation_r2 > VALIDATION_THRESHOLD].shape[0]\n",
    "holdout_Y_pred = np.zeros(shape=(holdout_X.shape[0], NUM_MODELS), dtype=np.float32)\n",
    "test_Y_pred = np.zeros(shape=(test_df.shape[0], NUM_MODELS), dtype=np.float32)\n",
    "\n",
    "count = 0\n",
    "for row in perf_stacked_df.itertuples():\n",
    "    fold, model_id, train_r2, validation_r2 = row[1], row[2], row[3], row[4]\n",
    "    if validation_r2 < 0.4:\n",
    "        continue\n",
    "    model = pickle.load(open(os.path.join(MODELS_PATH, model_id + '.stacked'), 'rb'))\n",
    "    test_Y_pred[:, count] = model.predict(test_X_stacked)\n",
    "    holdout_Y_pred[:, count] = model.predict(holdout_X_stacked)\n",
    "    count += 1\n",
    "\n",
    "holdout_Y_avg_stacked = np.mean(holdout_Y_pred, axis=1)\n",
    "test_Y_avg_stacked = np.mean(test_Y_pred, axis=1)\n",
    "test_Y_avg_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holdout_r2_ensemble 0.583066122756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted average of predictions\n",
    "holdout_Y_ensembled = holdout_Y_avg * 0.5 + holdout_Y_avg_stacked * 0.5\n",
    "holdout_r2_ensemble = metrics.r2_score(holdout_Y, holdout_Y_ensembled)\n",
    "print('holdout_r2_ensemble', holdout_r2_ensemble)\n",
    "\n",
    "test_Y_ensemble_1 = test_Y_avg * 0.5 + test_Y_avg_stacked * 0.5\n",
    "test_Y_ensemble_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted average of predictions\n",
    "# holdout_Y_ensembled = holdout_Y_avg * 0.5 + holdout_Y_stacked_pred * 0.5\n",
    "# holdout_r2_ensemble = metrics.r2_score(holdout_Y, holdout_Y_ensembled)\n",
    "# print('holdout_r2_ensemble', holdout_r2_ensemble)\n",
    "\n",
    "# Single stacked model prediction\n",
    "test_X_xgb = test_df[augmented_train_columns]\n",
    "stacked_Y = stacked_pipeline.predict(test_X_stacked)\n",
    "# stacked_Y.shape\n",
    "test_Y_ensemble_2 = test_Y_avg * 0.5 + stacked_Y * 0.5\n",
    "test_Y_ensemble_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated submission  /kaggle/dev/mercedes-benz-greener-manufacturing-data/submissions/submission-1498059783.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/dev/ashish/mercedes-benz-greener-manufacturing/merc/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission_df = test_df[['ID']]\n",
    "submission_df['y'] = test_Y_ensemble_2.tolist()\n",
    "submission_df.to_csv(os.path.join(SUBMISSION_PATH, 'submission-' + str(int(time.time())) + '.csv'), index=False)\n",
    "print('Generated submission ', os.path.join(SUBMISSION_PATH, 'submission-' + str(int(time.time())) + '.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
